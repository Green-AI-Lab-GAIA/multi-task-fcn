{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudando para a pasta ra√≠z\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.io_operations import read_yaml, read_tiff, save_yaml, fix_relative_paths, get_image_metadata, array2raster\n",
    "from src.utils import check_folder\n",
    "from src.metrics import evaluate_metrics, evaluate_component_metrics\n",
    "from sample_selection import get_components_stats, filter_components_by_mask\n",
    "\n",
    "from utils import *\n",
    "import os\n",
    "from os.path import dirname, join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from skimage.measure import label, find_contours\n",
    "from skimage.color import label2rgb, color_dict\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from millify import millify\n",
    "sns.set_style(\"whitegrid\")\n",
    "import torchvision.transforms.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE_FACTOR = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = f\"../{DOWNSAMPLE_FACTOR}x_amazon_input_data\"\n",
    "check_folder(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_folder(join(OUTPUT_FOLDER, \"segmentation\"))\n",
    "check_folder(join(OUTPUT_FOLDER, \"orthoimage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthoimage_path = r\"/u00/luiz.luz/multi-task-fcn/amazon_input_data/orthoimage/NOV_2017_FINAL_004.tif\"\n",
    "orthoimage = read_tiff(orthoimage_path)\n",
    "\n",
    "orthoimage_metadata = get_image_metadata(orthoimage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"../amazon_input_data/segmentation/test_set.tif\"\n",
    "test_set = read_tiff(\n",
    "    test_path\n",
    ")\n",
    "test_set_metadata = get_image_metadata(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../amazon_input_data/segmentation/train_set.tif\"\n",
    "train_set = read_tiff(\n",
    "    train_path\n",
    ")\n",
    "train_set_metadata = get_image_metadata(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = \"../amazon_input_data/mask.tif\"\n",
    "mask = read_tiff(\n",
    "    mask_path\n",
    ")\n",
    "mask_metadata = get_image_metadata(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_orthoimage = resize(orthoimage, (orthoimage.shape[0], orthoimage.shape[1]//DOWNSAMPLE_FACTOR, orthoimage.shape[2]//DOWNSAMPLE_FACTOR), anti_aliasing=True)\n",
    "resized_orthoimage = (resized_orthoimage*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_test_set = resize(test_set, (test_set.shape[0]//DOWNSAMPLE_FACTOR, test_set.shape[1]//DOWNSAMPLE_FACTOR), anti_aliasing=False, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train_set = resize(train_set, (train_set.shape[0]//DOWNSAMPLE_FACTOR, train_set.shape[1]//DOWNSAMPLE_FACTOR), anti_aliasing=False, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_mask = resize(mask, (mask.shape[0]//DOWNSAMPLE_FACTOR, mask.shape[1]//DOWNSAMPLE_FACTOR), anti_aliasing=False, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2raster(\n",
    "    path_to_save=join(OUTPUT_FOLDER,\"orthoimage\", \"orthoimage.tif\"),\n",
    "    array=resized_orthoimage,\n",
    "    image_metadata=orthoimage_metadata,\n",
    "    dtype=\"uint8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2raster(\n",
    "    path_to_save=join(OUTPUT_FOLDER, \"segmentation\", \"test_set.tif\"),\n",
    "    array=resized_test_set,\n",
    "    image_metadata=test_set_metadata,\n",
    "    dtype=\"uint8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2raster(\n",
    "    path_to_save=join(OUTPUT_FOLDER, \"segmentation\", \"train_set.tif\"),\n",
    "    array=resized_train_set,\n",
    "    image_metadata=train_set_metadata,\n",
    "    dtype=\"uint8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2raster(\n",
    "    path_to_save=join(OUTPUT_FOLDER, \"mask.tif\"),\n",
    "    array=resized_mask,\n",
    "    image_metadata=mask_metadata,\n",
    "    dtype=\"uint8\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
